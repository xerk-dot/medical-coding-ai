# AI Model Consensus Independence Analysis Report

## Executive Summary

This analysis examined which AI models showed the best consistency and independence from incorrect consensus decisions in medical coding questions. Out of 100 consensus decisions, 26 were incorrect (74% accuracy). The study reveals concerning patterns of groupthink while identifying models with superior independent reasoning capabilities.

## Key Findings

### ðŸ† Top Performing Models for Independent Decision-Making


1. **Dr. Gemini Pro the 2.5th**
   - Independence: 15.4% (4/26 correct when consensus wrong)
   - Individual Accuracy: 73.0%
   - Resisted wrong consensus on questions: 1, 70, 75, 81

2. **Dr. Claude Sonnet the 3.7th**
   - Independence: 15.4% (4/26 correct when consensus wrong)
   - Individual Accuracy: 71.0%
   - Resisted wrong consensus on questions: 34, 47, 70, 75

3. **Dr. Mistral Medium** 
   - Independence: 19.2% (5/26 correct when consensus wrong) - **HIGHEST INDEPENDENCE**
   - Individual Accuracy: 63.0%
   - Resisted wrong consensus on questions: 1, 12, 33, 38, 81

### Widespread Groupthink Problem

- **15 out of 26 wrong consensus questions** had NO models vote correctly in the final round
- Questions with 100% groupthink: 7, 11, 17, 20, 23, 24, 30, 41, 46, 57, 59, 64, 65, 91, 97
- This represents 57% of wrong decisions where ALL models were swayed by group pressure

### ðŸ“ˆ Independence Patterns

**Models with >10% Independence (6 total):**
- Dr. Mistral Medium (19.2%)
- Dr. Gemini Pro the 2.5th (15.4%)  
- Dr. Claude Sonnet the 3.7th (15.4%)
- Dr. Gemini Flash Preview the 2.5th (11.5%)
- Dr. Gemini Flash the 2.5th (11.5%)
- Dr. GPT 4o Mini (11.5%)